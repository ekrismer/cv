{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from enum import Enum\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Used Dataset\n",
    "\n",
    "We used the dataset CIFAR10 for training and testing our neural networks. The dataset consists of a total of 60000 colour images, which are split into 50000 training images and 10000 test images. Each image has a resolution of 32x32 pixel. \n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.  \n",
    "The Training set is further split into 5 Batches Ã  10000 images. Each training batch can have a different amount of pictures from the ten classes, whereas the test-set contains exactly 1000 pictures of each class.\n",
    "Following Classes are available:  \n",
    "    * airplane\n",
    "    * automobile\n",
    "    * bird\n",
    "    * cat\n",
    "    * deer\n",
    "    * dog\n",
    "    * frog\n",
    "    * horse\n",
    "    * ship\n",
    "    * truck\n",
    "    \n",
    "The following images shows an example for all the classes and 10 random images:\n",
    "<img src=\"CIFAR-10-example.PNG\" width=\"450px\" alt=\"CIFAR-10 example\" title=\"CIFAR-10 example images\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchvision datasets are PILImage images in range [0, 1]<br>\n",
    "=> transform them to normalized Tensors in range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data zero-padded by 4 pixels on each side, randomly cropped to a 32x32 image and eventually flipped horizontally\n",
    "# zero padding according to reference [24] - https://arxiv.org/pdf/1409.5185.pdf\n",
    "tf_train = transforms.Compose(\n",
    "    [transforms.RandomCrop(size=32, padding=4),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # image = (image - mean) / std\n",
    "     ])\n",
    "\n",
    "# test data is simply normalized\n",
    "tf_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # image = (image - mean) / std\n",
    "     ])\n",
    "\n",
    "class NeuralNet(Enum):\n",
    "    Net = 1\n",
    "    ResNet34 = 2\n",
    "    ResNet50 = 3\n",
    "    \n",
    "#select network to be used for training\n",
    "network = NeuralNet.Net\n",
    "\n",
    "# labels of the ten classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "examplesCnt = 8 # how many sample images with ground truth/prediction shall be printed\n",
    "\n",
    "batchSize = 200 # utilize parallel processing power of GPU, further increasing this number doesn't seem to have any effect\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=tf_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=tf_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# get some random training images\n",
    "images, labels = iter(trainloader).next()\n",
    "images = images[0:examplesCnt]\n",
    "labels = labels[0:examplesCnt]\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(', '.join('%5s' % classes[labels[j]] for j in range(examplesCnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural networks:\n",
    "\n",
    "We decided to use 3 networks and compare the results each network gives.\n",
    "\n",
    "Note: We adapted the learning rate for all networks, the exact approach will be noted for the optimizer\n",
    "\n",
    "<b> Convulutional neural network </b>\n",
    "As a starter we used the Convolutional neural network from pytorch (https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). We did not use an exact copy, but tried to optimize and increase the speed of the training process.\n",
    "In order to increase speed we raised the batch-size from originally 4 to 200. We stopped at 200 because there was no further improvment regarding the computation time.\n",
    "In order to adapt to the new batch-size we had to increase our learning rate(originally 0.001). Since the optimizer now has more images for computing the gradient. Hence it's a better approximation needs a bigger learning rate in order to efficiently improve the result. Without a larger learning rate we would need way more epoches to compensate the more precise gradient. \n",
    "\n",
    "Additional we decided to increase the input and output layers for the convolutions. Our thoughtprocess behind this, was to increase accuracy. Looking at more features from a picture should increase learning accuracy and lead to a better result. We tried with increasing inputplanes and stopped once we stopped noticing improvment in accuracy.\n",
    "Hence the following 3 computations changed:\n",
    "\n",
    "<b>Network definition:</b>  \n",
    "self.conv1 = nn.Conv2d(3, 6, 5) -> self.conv1 = nn.Conv2d(3, 48, 5)  \n",
    "self.conv2 = nn.Conv2d(6, 16, 5) -> self.conv2 = nn.Conv2d(48, 64, 5)\n",
    "\n",
    "<b>Forward-Step</b> (This change was necessary for the network to work, not for improvment. Otherwise the dimensions for the function would not match)  \n",
    "x = x.view(-1, 16 * 5 * 5) -> x = x.view(-1, 64 * 5 * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes, \n",
    "        out_planes, \n",
    "        kernel_size=1, \n",
    "        stride=stride, \n",
    "        #padding=0\n",
    "        bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, \n",
    "                     out_planes, \n",
    "                     kernel_size=3, \n",
    "                     stride=stride,\n",
    "                     padding=1, # with stride=1 this preserves dimension\n",
    "                     bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv2d: input, output, kernel size, (stride=1, padding=0)\n",
    "        self.conv1 = nn.Conv2d(3, 48, 5) # 3 input image channel, 64 output channels, 5x5 square convolution\n",
    "        self.conv2 = nn.Conv2d(48, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # 10 classses output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 48 channels: conv results in 28x28 (image-kernel+1), pool => 14x14 image size\n",
    "        #print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 64 channels: conv results in 10x10 (image-kernel+1), pool => 5x5 image size\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet Implementations\n",
    "\n",
    "We choose two Resnet Implementations, ResNet-34 and Resnet-50. Since both use different Blocks \n",
    "(Resnet-34 uses BasicBlocks, Resnet-50 usese Bottleneck Blocks). Theses networks are not too far apart, regarding layer \n",
    "size, but use different kind of Blocks, so we were interested to see how this difference would impact accuracy and runtime.\n",
    "\n",
    "### Resnet-34 BasisBlock\n",
    "\n",
    "For the BasicBlock Implementation we used the lecture as a template.  \n",
    "\n",
    "![BasicBlock](BasicBlock.png)\n",
    "\n",
    "### Resnet-34\n",
    "\n",
    "For the the Resnet-34 we tried to implement the network while using the paper as a model. We noticed, that the implementation from our paper is very similar to the one pytorch(same holds for Resnet-50). \n",
    "    * Each resnet useses either Basic- or BottleneckBlocks, but never both\n",
    "    * Both use the same data processing technique (# TODO state these techniques)\n",
    "    * Both use a Linear network in order to map the results to our ten classes\n",
    "    \n",
    "In the paper way more epoches are used than we could handle, since we are missing the computational power. Hence we tried to adjust the learning rate in order to achieve a fast but still accurate result. \n",
    "Tweaks we did #TODO\n",
    "\n",
    "### Resnet-50 BottleneckBlock\n",
    "\n",
    "For the BottleneckBlock we also used the template from the lecture.  \n",
    "\n",
    "![BotleneckBlock](BottleneckBlock.png)\n",
    "\n",
    "#### Resnet-50 \n",
    "\n",
    "Tweaks we did #TODO\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        3x3 convolution inplanes->outplanes \n",
    "        (spatial size maintained), BN + ReLU\n",
    "        \"\"\" \n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \"\"\"\n",
    "        3x3 convolution inplanes->outplanes \n",
    "        (spatial size maintained) + BN\n",
    "        \"\"\" \n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        # needed to fix dimension incompatibility\n",
    "        self.stride = stride # not actually used in class itself\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x # preserve input for identity functionality\n",
    "\n",
    "        # conv->bn->relu\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # conv->bn\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        \"\"\"\n",
    "        At that point, we check if a downsampling needs to be \n",
    "        applied on x, such that F(x)+x can be computed.\n",
    "        \"\"\"\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        # shortcut connection: x + F(x)\n",
    "        out += residual\n",
    "        \n",
    "        # building block ends with ReLU\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    The expansion factor controls the number of output \n",
    "    channels of the last 1x1 convolution layer.\n",
    "    \"\"\"\n",
    "    expansion = 4  \n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cuda device if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet34 has a 3-4-6-3 structure of BasicBlocks\n",
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, zero_init_residual=False):\n",
    "        super(ResNet34, self).__init__()\n",
    "        \n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        # layer 1: 3 times BasicBlock with 64 planes, no dimension increase\n",
    "        planes = 64\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(self.inplanes, planes, 1, None))\n",
    "        self.inplanes = planes * BasicBlock.expansion\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        self.layer1 = nn.Sequential(*layers)\n",
    "    \n",
    "        # layer 2: 4 times BasicBlock with 128 planes, dimension increase!\n",
    "        planes = 128\n",
    "        layers = []\n",
    "        down_fn = nn.Sequential(conv1x1(self.inplanes, planes * BasicBlock.expansion, stride=2), nn.BatchNorm2d(planes * BasicBlock.expansion) )\n",
    "        layers.append(BasicBlock(self.inplanes, planes, 2, down_fn))\n",
    "        self.inplanes = planes * BasicBlock.expansion\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        self.layer2 = nn.Sequential(*layers)\n",
    "    \n",
    "        # layer 3: 6 times BasicBlock with 256 planes, dimension increase!\n",
    "        planes = 256\n",
    "        layers = []\n",
    "        down_fn = nn.Sequential(conv1x1(self.inplanes, planes * BasicBlock.expansion, stride=2), nn.BatchNorm2d(planes * BasicBlock.expansion) )\n",
    "        layers.append(BasicBlock(self.inplanes, planes, 2, down_fn))\n",
    "        self.inplanes = planes * BasicBlock.expansion\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        self.layer3 = nn.Sequential(*layers)\n",
    "    \n",
    "        # layer 4: 3 times BasicBlock with 512 planes, dimension increase!\n",
    "        planes = 512\n",
    "        layers = []\n",
    "        down_fn = nn.Sequential(conv1x1(self.inplanes, planes * BasicBlock.expansion, stride=2), nn.BatchNorm2d(planes * BasicBlock.expansion) )\n",
    "        layers.append(BasicBlock(self.inplanes, planes, 2, down_fn))\n",
    "        self.inplanes = planes * BasicBlock.expansion\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        layers.append(BasicBlock(self.inplanes, planes))\n",
    "        self.layer4 = nn.Sequential(*layers)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n",
    "\n",
    "        # ToDo\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # ToDo\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 has a 3-4-6-3 structure of Bottlenecks\n",
    "class ResNet50(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, zero_init_residual=False):\n",
    "        super(ResNet50, self).__init__()\n",
    "        \n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        # layer 1: 3 times Bottleneck with 64 planes, no dimension increase\n",
    "        planes = 64\n",
    "        layers = []\n",
    "        down_fn = nn.Sequential(conv1x1(self.inplanes, planes * Bottleneck.expansion, stride=1), nn.BatchNorm2d(planes * Bottleneck.expansion) )\n",
    "        layers.append(Bottleneck(self.inplanes, planes, 1, down_fn))\n",
    "        self.inplanes = planes * Bottleneck.expansion\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        self.layer1 = nn.Sequential(*layers)\n",
    "    \n",
    "        # layer 2: 4 times Bottleneck with 128 planes, dimension increase!\n",
    "        planes = 128\n",
    "        layers = []\n",
    "        down_fn = nn.Sequential(conv1x1(self.inplanes, planes * Bottleneck.expansion, stride=2), nn.BatchNorm2d(planes * Bottleneck.expansion) )\n",
    "        layers.append(Bottleneck(self.inplanes, planes, 2, down_fn))\n",
    "        self.inplanes = planes * Bottleneck.expansion\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        self.layer2 = nn.Sequential(*layers)\n",
    "    \n",
    "        # layer 3: 6 times Bottleneck with 256 planes, dimension increase!\n",
    "        planes = 256\n",
    "        layers = []\n",
    "        down_fn = nn.Sequential(conv1x1(self.inplanes, planes * Bottleneck.expansion, stride=2), nn.BatchNorm2d(planes * Bottleneck.expansion) )\n",
    "        layers.append(Bottleneck(self.inplanes, planes, 2, down_fn))\n",
    "        self.inplanes = planes * Bottleneck.expansion\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        self.layer3 = nn.Sequential(*layers)\n",
    "    \n",
    "        # layer 4: 3 times Bottleneck with 512 planes, dimension increase!\n",
    "        planes = 512\n",
    "        layers = []\n",
    "        down_fn = nn.Sequential(conv1x1(self.inplanes, planes * Bottleneck.expansion, stride=2), nn.BatchNorm2d(planes * Bottleneck.expansion) )\n",
    "        layers.append(Bottleneck(self.inplanes, planes, 2, down_fn))\n",
    "        self.inplanes = planes * Bottleneck.expansion\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        layers.append(Bottleneck(self.inplanes, planes))\n",
    "        self.layer4 = nn.Sequential(*layers)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n",
    "\n",
    "        # ToDo\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # ToDo\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which network should be used:\n",
    "# every epoch has 250 iterations with each 200 images\n",
    "if network == NeuralNet.Net:\n",
    "    net = Net()\n",
    "    epochCnt = 40\n",
    "elif network == NeuralNet.ResNet34:\n",
    "    net = ResNet34()\n",
    "    epochCnt = 70\n",
    "elif network == NeuralNet.ResNet50:\n",
    "    net = ResNet50()\n",
    "    epochCnt = 50\n",
    "else:\n",
    "    sys.exit(\"invalid network type!\")\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "# print number of paramters in currently selected network\n",
    "netParamCnt = 0\n",
    "for p in net.parameters(): netParamCnt+=p.numel()\n",
    "print(\"%s has %d parameters.\" % (network.name, netParamCnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Loss function and optimizer:\n",
    "\n",
    "Additional to the optimizer we used a scheduler to adapt our learingn rate. In the paper the same technique is used in order to achieve better results. As a consequence we needed to increase our epoches, so the scheduler could work efficiently (decrease learning rate at least two times). This also lead to an increased amount of time our network needed for the learning proccess.\n",
    "\n",
    "For the loss we used a Classification Cross-Entropy loss and SGD with momentum. This is the same in pytorch as well as our paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[32000, 48000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_start = time.process_time()\n",
    "\n",
    "for epoch in range(epochCnt):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 1): # 50.000 test images => 250 iterations with each 200 images\n",
    "        scheduler.step()\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs) # 10 class output\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 25 == 0:    # print every 25 mini-batches of size 200\n",
    "            print('[%5d] loss: %.3f' %\n",
    "                  (epoch * 250 + i, running_loss / 25))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training (duration %.3f sec)' % (time.process_time() - time_start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the network\n",
    "\n",
    "Original we used two epoches for the non-residual network. While using the Res-Net we noticed that 2 epoches were not enough especially when using a scheduler for the learning rate. We decided to use 5 epoch in order to get at least two learning-rate reductions. This should be enough since we did not notice any additional change to our loss. Especially for lower learning rates.\n",
    "\n",
    "In order to check the results our networks have achieved we decided to use the template from pytorch and the lecture, splitting in in 3 parts:\n",
    "    * Check 8 sample images and their computed labels\n",
    "    * Total Accuracy\n",
    "    * Class Accuracy\n",
    "\n",
    "<b>Sample Images with computed labels:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "images = images[0:examplesCnt]\n",
    "labels = labels[0:examplesCnt]\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ', '.join('%5s' % classes[labels[j]] for j in range(examplesCnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move input to cuda device if available\n",
    "images = images.to(device)\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Predicted Classes from our network:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ', '.join('%5s' % classes[predicted[j]] for j in range(examplesCnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Total Accuracy:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %2d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Class Accuracy:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(batchSize):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
