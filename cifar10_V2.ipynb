{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training a Classifier\n",
    "=====================\n",
    "\n",
    "This is it. You have seen how to define neural networks, compute loss and \n",
    "updates to the weights of the network.\n",
    "\n",
    "Now you might be thinking,\n",
    "\n",
    "What about data?\n",
    "----------------\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing CIFAR10\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # image = (image - mean) / std\n",
    "     ])\n",
    "\n",
    "batchSize = 200\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "examplesCnt = 8 # how many images with ground truth/prediction shall be printed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dog   cat   car  ship   cat   cat  ship   dog\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "images = images[0:examplesCnt]\n",
    "labels = labels[0:examplesCnt]\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(examplesCnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolutional Neural Network\n",
    "\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 980 Ti\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# use cuda device if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(device)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv2d: input, output, kernel size, (stride=1, padding=0)\n",
    "        self.conv1 = nn.Conv2d(3, 48, 5) # 3 input image channel, 48 output channels, 5x5 square convolution\n",
    "        self.conv2 = nn.Conv2d(48, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # 10 classses output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # conv results in 28x28 (image-kernel+1), pool => 14x14\n",
    "        x = self.pool(F.relu(self.conv2(x))) # conv results in 10x10 (image-kernel+1), pool => 5x5\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "net = resnet34().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9) # ToDo!\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.1, patience=100, verbose=True, threshold=0.03 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.0907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,    25] loss: 3.859\n",
      "tensor(2.4041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,    50] loss: 2.660\n",
      "tensor(2.5178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,    75] loss: 2.508\n",
      "tensor(2.3129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,   100] loss: 2.503\n",
      "tensor(1.9663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,   125] loss: 1.991\n",
      "tensor(1.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9357, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,   150] loss: 1.908\n",
      "tensor(2.1652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,   175] loss: 1.949\n",
      "tensor(1.8057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,   200] loss: 1.929\n",
      "tensor(1.6273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,   225] loss: 1.776\n",
      "tensor(1.7700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1,   250] loss: 1.770\n",
      "tensor(1.6520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.4152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,    25] loss: 1.808\n",
      "tensor(1.5598, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,    50] loss: 1.675\n",
      "tensor(1.7975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,    75] loss: 1.689\n",
      "tensor(1.6319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,   100] loss: 1.568\n",
      "tensor(1.4585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,   125] loss: 1.582\n",
      "tensor(1.5674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch   390: reducing learning rate of group 0 to 1.0000e-02.\n",
      "tensor(1.4782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,   150] loss: 1.513\n",
      "tensor(1.5995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4196, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,   175] loss: 1.485\n",
      "tensor(1.5454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,   200] loss: 1.418\n",
      "tensor(1.3751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,   225] loss: 1.412\n",
      "tensor(1.3486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[2,   250] loss: 1.403\n",
      "tensor(1.4534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,    25] loss: 1.390\n",
      "tensor(1.5502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch   539: reducing learning rate of group 0 to 1.0000e-03.\n",
      "tensor(1.4158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4673, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,    50] loss: 1.388\n",
      "tensor(1.2757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,    75] loss: 1.359\n",
      "tensor(1.3595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,   100] loss: 1.381\n",
      "tensor(1.3024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,   125] loss: 1.357\n",
      "tensor(1.2930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch   640: reducing learning rate of group 0 to 1.0000e-04.\n",
      "tensor(1.4977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,   150] loss: 1.362\n",
      "tensor(1.4183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,   175] loss: 1.332\n",
      "tensor(1.2849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,   200] loss: 1.361\n",
      "tensor(1.2973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,   225] loss: 1.386\n",
      "tensor(1.4324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch   741: reducing learning rate of group 0 to 1.0000e-05.\n",
      "tensor(1.3740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[3,   250] loss: 1.367\n",
      "tensor(1.4461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,    25] loss: 1.385\n",
      "tensor(1.3128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,    50] loss: 1.314\n",
      "tensor(1.5009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3193, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,    75] loss: 1.382\n",
      "tensor(1.3931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch   842: reducing learning rate of group 0 to 1.0000e-06.\n",
      "tensor(1.3783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,   100] loss: 1.365\n",
      "tensor(1.3247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,   125] loss: 1.372\n",
      "tensor(1.3215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,   150] loss: 1.352\n",
      "tensor(1.4038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,   175] loss: 1.335\n",
      "tensor(1.2807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,   200] loss: 1.346\n",
      "tensor(1.3056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3884, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,   225] loss: 1.356\n",
      "tensor(1.2717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[4,   250] loss: 1.348\n",
      "tensor(1.4414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[5,    25] loss: 1.344\n",
      "tensor(1.3332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch  1043: reducing learning rate of group 0 to 1.0000e-07.\n",
      "tensor(1.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[5,    50] loss: 1.357\n",
      "tensor(1.1711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[5,    75] loss: 1.359\n",
      "tensor(1.2512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3300, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[5,   100] loss: 1.358\n",
      "tensor(1.2515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[5,   125] loss: 1.370\n",
      "tensor(1.4499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3653, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.process_time()\n",
    "\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs) # 10 class output\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 25 == 24:    # print every 25 mini-batches of size 200\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 25))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training (duration %.3f sec)' % (time.process_time() - time_start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "images = images[0:examplesCnt]\n",
    "labels = labels[0:examplesCnt]\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(examplesCnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move input to cuda device if available\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "Higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(examplesCnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
